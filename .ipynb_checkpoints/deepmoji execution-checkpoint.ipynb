{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "from tensorflow.python.keras import backend as k\n",
    "from tensorflow import keras  \n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Input, Bidirectional, Embedding, Dense, Dropout, SpatialDropout1D, LSTM, Activation\n",
    "from tensorflow.keras.regularizers import L1L2\n",
    "from tensorflow.python.framework import ops\n",
    "ops.reset_default_graph()\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from os.path import exists\n",
    "import h5py\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras.layers import InputSpec, Layer\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_to_embedding(pretrain_weights, random_init_weights):\n",
    "    \"\"\" Uses pretrained weights for the tokens already in the vocabulary.\n",
    "        Remaining weights will be left with the random initialization. \"\"\"\n",
    "\n",
    "    pretrain_weights = deepcopy(pretrain_weights)\n",
    "    if type(pretrain_weights) == list:\n",
    "        pretrain_weights = pretrain_weights[0]\n",
    "    if type(random_init_weights) == list:\n",
    "        random_init_weights = random_init_weights[0]\n",
    "\n",
    "    nb_old_tokens = np.shape(pretrain_weights)[0]\n",
    "    random_init_weights[:nb_old_tokens] = pretrain_weights\n",
    "\n",
    "    # must be returned as a list to be properly inserted into Keras model\n",
    "    return [random_init_weights]\n",
    "\n",
    "\n",
    "def get_weights_from_hdf5(filepath):\n",
    "    \"\"\" Loads the weights from a saved Keras model into numpy arrays.\n",
    "        The weights are saved using Keras 2.0 so we don't need all the\n",
    "        conversion functionality for handling old weights.\n",
    "    \"\"\"\n",
    "\n",
    "    with h5py.File(filepath, mode='r') as f:\n",
    "        layer_names = [n.decode('utf8') for n in f.attrs['layer_names']]\n",
    "        layer_weights = []\n",
    "        for k, l_name in enumerate(layer_names):\n",
    "            g = f[l_name]\n",
    "            weight_names = [n.decode('utf8') for n in g.attrs['weight_names']]\n",
    "            weight_values = [g[weight_name][:] for weight_name in weight_names]\n",
    "            if len(weight_values):\n",
    "                layer_weights.append([l_name, weight_names, weight_values])\n",
    "        return layer_weights\n",
    "def load_specific_weights(model, weight_path, exclude_names=[], extend_embedding=0, verbose=True):\n",
    "    \"\"\" Loads model weights from the given file path, excluding any\n",
    "        given layers.\n",
    "    # Arguments:\n",
    "        model: Model whose weights should be loaded.\n",
    "        weight_path: Path to file containing model weights.\n",
    "        exclude_names: List of layer names whose weights should not be loaded.\n",
    "        extend_embedding: Number of new words being added to vocabulary.\n",
    "        verbose: Verbosity flag.\n",
    "    # Raises:\n",
    "        ValueError if the file at weight_path does not exist.\n",
    "    \"\"\"\n",
    "    if not exists(weight_path):\n",
    "        raise ValueError('ERROR (load_weights): The weights file at {} does '\n",
    "                         'not exist. Refer to the README for instructions.'\n",
    "                         .format(weight_path))\n",
    "\n",
    "    if extend_embedding and 'embedding' in exclude_names:\n",
    "        raise ValueError('ERROR (load_weights): Cannot extend a vocabulary '\n",
    "                         'without loading the embedding weights.')\n",
    "\n",
    "    # Copy only weights from the temporary model that are wanted\n",
    "    # for the specific task (e.g. the Softmax is often ignored)\n",
    "    layer_weights = get_weights_from_hdf5(weight_path)\n",
    "    for i, w in enumerate(layer_weights):\n",
    "        l_name = w[0]\n",
    "        weight_names = w[1]\n",
    "        weight_values = w[2]\n",
    "\n",
    "        if l_name in exclude_names:\n",
    "            if verbose:\n",
    "                print('Ignoring weights for {}'.format(l_name))\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            model_l = model.get_layer(name=l_name)\n",
    "        except ValueError:\n",
    "            raise ValueError(\"Weights had layer {},\".format(l_name) +\n",
    "                             \" but could not find this layer in model.\")\n",
    "        if verbose:\n",
    "            print('Loading weights for {}'.format(l_name))\n",
    "\n",
    "        # extend embedding layer to allow new randomly initialized words\n",
    "        # if requested. Otherwise, just load the weights for the layer.\n",
    "        if type(model_l) is Embedding and extend_embedding > 0:\n",
    "            comb_weights = append_to_embedding(weight_values,\n",
    "                                               model_l.get_weights())\n",
    "            model_l.set_weights(comb_weights)\n",
    "            if verbose:\n",
    "                print('Extended vocabulary for embedding layer ' +\n",
    "                      'from {} to {} tokens.'.format(\n",
    "                          NB_TOKENS, NB_TOKENS + extend_embedding))\n",
    "        else:\n",
    "            model_l.set_weights(weight_values)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class AttentionWeightedAverage(Layer):\n",
    "    \"\"\"\n",
    "    Computes a weighted average of the different channels across timesteps.\n",
    "    Uses 1 parameter pr. channel to compute the attention value for a single timestep.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, return_attention=False, **kwargs):\n",
    "        self.init = initializers.get('uniform')\n",
    "        self.supports_masking = True\n",
    "        self.return_attention = return_attention\n",
    "        super(AttentionWeightedAverage, self).__init__(** kwargs)\n",
    "        \n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'return_attention': self.return_attention,\n",
    "        }\n",
    "        base_config = super(AttentionWeightedAverage, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.input_spec = [InputSpec(ndim=3)]\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight(shape=(input_shape[2], 1),\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 initializer=self.init)\n",
    "        self.trainable_weights.append([self.W])\n",
    "        super(AttentionWeightedAverage, self).build(input_shape)\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        # computes a probability distribution over the timesteps\n",
    "        # uses 'max trick' for numerical stability\n",
    "        # reshape is done to avoid issue with Tensorflow\n",
    "        # and 1-dimensional weights\n",
    "        logits = K.dot(x, self.W)\n",
    "        x_shape = K.shape(x)\n",
    "        logits = K.reshape(logits, (x_shape[0], x_shape[1]))\n",
    "        ai = K.exp(logits - K.max(logits, axis=-1, keepdims=True))\n",
    "\n",
    "        # masked timesteps have zero weight\n",
    "        if mask is not None:\n",
    "            mask = K.cast(mask, K.floatx())\n",
    "            ai = ai * mask\n",
    "        att_weights = ai / (K.sum(ai, axis=1, keepdims=True) + K.epsilon())\n",
    "        weighted_input = x * K.expand_dims(att_weights)\n",
    "        result = K.sum(weighted_input, axis=1)\n",
    "        if self.return_attention:\n",
    "            return [result, att_weights]\n",
    "        return result\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return self.compute_output_shape(input_shape)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        output_len = input_shape[2]\n",
    "        if self.return_attention:\n",
    "            return [(input_shape[0], output_len), (input_shape[0], input_shape[1])]\n",
    "        return (input_shape[0], output_len)\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        if isinstance(input_mask, list):\n",
    "            return [None] * len(input_mask)\n",
    "        else:\n",
    "            return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deepmoji_architecture(nb_classes, nb_tokens, maxlen, feature_output=False, embed_dropout_rate=0, final_dropout_rate=0, embed_l2=1E-6, return_attention=False):\n",
    "    \"\"\"\n",
    "    Returns the DeepMoji architecture uninitialized and\n",
    "    without using the pretrained model weights.\n",
    "    # Arguments:\n",
    "        nb_classes: Number of classes in the dataset.\n",
    "        nb_tokens: Number of tokens in the dataset (i.e. vocabulary size).\n",
    "        maxlen: Maximum length of a token.\n",
    "        feature_output: If True the model returns the penultimate\n",
    "                        feature vector rather than Softmax probabilities\n",
    "                        (defaults to False).\n",
    "        embed_dropout_rate: Dropout rate for the embedding layer.\n",
    "        final_dropout_rate: Dropout rate for the final Softmax layer.\n",
    "        embed_l2: L2 regularization for the embedding layerl.\n",
    "    # Returns:\n",
    "        Model with the given parameters.\n",
    "    \"\"\"\n",
    "    # define embedding layer that turns word tokens into vectors\n",
    "    # an activation function is used to bound the values of the embedding\n",
    "    model_input = Input(shape=(maxlen,), dtype='int32')\n",
    "    embed_reg = L1L2(l2=embed_l2) if embed_l2 != 0 else None\n",
    "    embed = Embedding(input_dim=nb_tokens,\n",
    "                      output_dim=256,\n",
    "                      mask_zero=True,\n",
    "                      input_length=maxlen,\n",
    "                      embeddings_regularizer=embed_reg,\n",
    "                      name='embedding')\n",
    "    x = embed(model_input)\n",
    "    x = Activation('tanh')(x)\n",
    "\n",
    "    # entire embedding channels are dropped out instead of the\n",
    "    # normal Keras embedding dropout, which drops all channels for entire words\n",
    "    # many of the datasets contain so few words that losing one or more words can alter the emotions completely\n",
    "    if embed_dropout_rate != 0:\n",
    "        embed_drop = SpatialDropout1D(embed_dropout_rate, name='embed_drop')\n",
    "        x = embed_drop(x)\n",
    "\n",
    "    # skip-connection from embedding to output eases gradient-flow and allows access to lower-level features\n",
    "    # ordering of the way the merge is done is important for consistency with the pretrained model\n",
    "    lstm_0_output = Bidirectional(LSTM(512, return_sequences=True), name=\"bi_lstm_0\")(x)\n",
    "    lstm_1_output = Bidirectional(LSTM(512, return_sequences=True), name=\"bi_lstm_1\")(lstm_0_output)\n",
    "    x = concatenate([lstm_1_output, lstm_0_output, x])\n",
    "\n",
    "    # if return_attention is True in AttentionWeightedAverage, an additional tensor\n",
    "    # representing the weight at each timestep is returned\n",
    "    weights = None\n",
    "    x = AttentionWeightedAverage(name='attlayer', return_attention=return_attention)(x)\n",
    "    if return_attention:\n",
    "        x, weights = x\n",
    "\n",
    "    if not feature_output:\n",
    "        # output class probabilities\n",
    "        if final_dropout_rate != 0:\n",
    "            x = Dropout(final_dropout_rate)(x)\n",
    "\n",
    "        if nb_classes > 2:\n",
    "            outputs = [Dense(nb_classes, activation='softmax', name='softmax')(x)]\n",
    "        else:\n",
    "            outputs = [Dense(1, activation='sigmoid', name='softmax')(x)]\n",
    "    else:\n",
    "        # output penultimate feature vector\n",
    "        outputs = [x]\n",
    "\n",
    "    if return_attention:\n",
    "        # add the attention weights to the outputs if required\n",
    "        outputs.append(weights)\n",
    "\n",
    "    return Model(inputs=[model_input], outputs=outputs, name=\"DeepMoji\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deepmoji_feature_encoding(maxlen, weight_path, return_attention=False):\n",
    "    \"\"\" Loads the pretrained DeepMoji model for extracting features\n",
    "        from the penultimate feature layer. In this way, it transforms\n",
    "        the text into its emotional encoding.\n",
    "    # Arguments:\n",
    "        maxlen: Maximum length of a sentence (given in tokens).\n",
    "        weight_path: Path to model weights to be loaded.\n",
    "        return_attention: If true, output will be weight of each input token\n",
    "            used for the prediction\n",
    "    # Returns:\n",
    "        Pretrained model for encoding text into feature vectors.\n",
    "    \"\"\"\n",
    "\n",
    "    model = deepmoji_architecture(nb_classes=None, nb_tokens=NB_TOKENS, maxlen=maxlen, feature_output=True, return_attention=return_attention)\n",
    "    load_specific_weights(model, weight_path, exclude_names=['softmax'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRETRAINED_PATH = 'deepmoji_weights.hdf5'\n",
    "VOCAB_PATH = 'vocabulary.json'\n",
    "NB_TOKENS = 50000\n",
    "NB_EMOJI_CLASSES = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights for embedding\n",
      "Loading weights for bi_lstm_0\n",
      "Loading weights for bi_lstm_1\n",
      "Loading weights for attlayer\n",
      "Ignoring weights for softmax\n",
      "Model: \"DeepMoji\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 30)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 30, 256)      12800000    input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 30, 256)      0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bi_lstm_0 (Bidirectional)       (None, 30, 1024)     3149824     activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bi_lstm_1 (Bidirectional)       (None, 30, 1024)     6295552     bi_lstm_0[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 30, 2304)     0           bi_lstm_1[0][0]                  \n",
      "                                                                 bi_lstm_0[0][0]                  \n",
      "                                                                 activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "attlayer (AttentionWeightedAver (None, 2304)         2304        concatenate_2[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 22,247,680\n",
      "Trainable params: 22,247,680\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = deepmoji_feature_encoding(30, PRETRAINED_PATH)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = model.predict(k)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
